# Application Architecture

## ğŸ“‚ Project Structure

```
/
â”œâ”€â”€ index.html          # Entry point
â”œâ”€â”€ App.tsx             # Main Router & Global State (Theme, Mode)
â”œâ”€â”€ types.ts            # TypeScript definitions for Models, Nodes, Messages
â”œâ”€â”€ components/         # UI Components
â”‚   â”œâ”€â”€ Chat.tsx        # Main Chat Interface (State: Messages, Inputs)
â”‚   â”œâ”€â”€ GraphCanvas.tsx # Node System (State: Nodes, Connections, Pan/Zoom)
â”‚   â”œâ”€â”€ KnowledgeBase.tsx # RAG Interface (Uploads, List)
â”‚   â”œâ”€â”€ Settings.tsx    # API Key Management (LocalStorage)
â”‚   â”œâ”€â”€ Sidebar.tsx     # Navigation
â”‚   â””â”€â”€ icons/          # SVG Icon collection
â”œâ”€â”€ services/           # Business Logic & API Calls
â”‚   â”œâ”€â”€ geminiService.ts # Google GenAI, OpenRouter, & Search API logic
â”‚   â””â”€â”€ ragService.ts    # Local Vector Store, Embeddings, Cosine Similarity
â””â”€â”€ utils/
    â””â”€â”€ fileUtils.ts    # Helpers for Base64 conversion
```

## ğŸ§  Key Logic Flows

### 1. The Chat System (`Chat.tsx` -> `geminiService.ts`)
*   **User Input**: Captured in `Chat.tsx`.
*   **Processing**:
    *   If **Tools** (Maps/Search) are active, `geminiService` constructs a tool-enabled request.
    *   If **Knowledge Base** is active, `ragService.search(query)` is called first. The context is prepended to the user prompt hiddenly.
*   **Execution**: `getChatResponse` routes the request to the correct provider (Gemini SDK, fetch for OpenRouter/Ollama).

### 2. The Graph System (`GraphCanvas.tsx`)
*   **State**: `nodes` array and `connections` array.
*   **Execution (`runNode`)**:
    1.  **Context Building**: Recursively finds parent nodes (`fromNodeId`) and gathers their `response` text.
    2.  **Tool Injection**: If external search (Tavily/Exa) is on, it fetches data *before* calling the LLM.
    3.  **Prompt Construction**: `[Parent Context] + [File Context] + [Search Results] + [Current Prompt]`.
    4.  **LLM Call**: Sends the massive prompt to Gemini.

### 3. The RAG System (`ragService.ts`)
*   **Client-Side Only**: This app does not use a Python backend (Pinecone/Chroma). It uses an **in-memory array**.
*   **Process**:
    1.  `addDocument`: text -> chunks -> `gemini-embedding-004` -> vector array.
    2.  `search`: query -> embedding -> cosine similarity against array -> top K chunks.

## ğŸ¨ Styling
*   **Tailwind CSS**: Used for all styling.
*   **Dark Mode**: Handled via a `dark` class on the `<html>` tag. Components use `dark:bg-gray-900` variants to adapt.
